{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Word--            --Stem--            \n",
      "program             program             \n",
      "programming         program             \n",
      "programer           program             \n",
      "programs            program             \n",
      "programmed          program             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/priyanshukumarsaw/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download(\"punkt\")\n",
    "# Initialize Python porter stemmer\n",
    "ps = PorterStemmer()\n",
    "# Example inflections to reduce\n",
    "example_words = [\"program\",\"programming\",\"programer\",\"programs\",\"programmed\"]\n",
    "# Perform stemming\n",
    "print(\"{0:20}{1:20}\".format(\"--Word--\",\"--Stem--\"))\n",
    "for word in example_words:\n",
    "   print (\"{0:20}{1:20}\".format(word, ps.stem(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Word--            --Stem--            \n",
      "I                   i                   \n",
      "have                have                \n",
      "three               three               \n",
      "visions             vision              \n",
      "for                 for                 \n",
      "India               india               \n",
      "In                  in                  \n",
      "3000                3000                \n",
      "years               year                \n",
      "of                  of                  \n",
      "our                 our                 \n",
      "history             histori             \n",
      "people              peopl               \n",
      "from                from                \n",
      "all                 all                 \n",
      "over                over                \n",
      "the                 the                 \n",
      "world               world               \n",
      "have                have                \n",
      "come                come                \n",
      "and                 and                 \n",
      "invaded             invad               \n",
      "us                  us                  \n",
      "captured            captur              \n",
      "our                 our                 \n",
      "lands               land                \n",
      "conquered           conquer             \n",
      "our                 our                 \n",
      "minds               mind                \n",
      "From                from                \n",
      "Alexander           alexand             \n",
      "onwards             onward              \n",
      "the                 the                 \n",
      "Greeks              greek               \n",
      "the                 the                 \n",
      "Turks               turk                \n",
      "the                 the                 \n",
      "Moguls              mogul               \n",
      "the                 the                 \n",
      "Portuguese          portugues           \n",
      "the                 the                 \n",
      "British             british             \n",
      "the                 the                 \n",
      "French              french              \n",
      "the                 the                 \n",
      "Dutch               dutch               \n",
      "all                 all                 \n",
      "of                  of                  \n",
      "them                them                \n",
      "came                came                \n",
      "and                 and                 \n",
      "looted              loot                \n",
      "us                  us                  \n",
      "took                took                \n",
      "over                over                \n",
      "what                what                \n",
      "was                 wa                  \n",
      "ours                our                 \n",
      "Yet                 yet                 \n",
      "we                  we                  \n",
      "have                have                \n",
      "not                 not                 \n",
      "done                done                \n",
      "this                thi                 \n",
      "to                  to                  \n",
      "any                 ani                 \n",
      "other               other               \n",
      "nation              nation              \n",
      "We                  we                  \n",
      "have                have                \n",
      "not                 not                 \n",
      "conquered           conquer             \n",
      "anyone              anyon               \n",
      "We                  we                  \n",
      "have                have                \n",
      "not                 not                 \n",
      "grabbed             grab                \n",
      "their               their               \n",
      "land                land                \n",
      "their               their               \n",
      "culture             cultur              \n",
      "their               their               \n",
      "history             histori             \n",
      "and                 and                 \n",
      "tried               tri                 \n",
      "to                  to                  \n",
      "enforce             enforc              \n",
      "our                 our                 \n",
      "way                 way                 \n",
      "of                  of                  \n",
      "life                life                \n",
      "on                  on                  \n",
      "them                them                \n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example_sentence = \"\"\"\n",
    "    I have three visions for India. In 3000 years of our history,\n",
    "    people from all over the world have come and invaded us, captured our  lands, conquered our minds.\n",
    "    From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "    the French, the Dutch, all of them came and looted us, took over what was ours.\n",
    "    Yet we have not done this to any other nation. We have not conquered anyone.\n",
    "    We have not grabbed their land, their culture,\n",
    "    their history and tried to enforce our way of life on them.\n",
    "    \"\"\"\n",
    "\n",
    "# Remove punctuation\n",
    "example_sentence_no_punct = example_sentence.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "# Create tokens\n",
    "word_tokens = word_tokenize(example_sentence_no_punct)\n",
    "\n",
    "# Perform stemming\n",
    "print(\"{0:20}{1:20}\".format(\"--Word--\",\"--Stem--\"))\n",
    "for word in word_tokens:\n",
    "    print (\"{0:20}{1:20}\".format(word, ps.stem(word)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/priyanshukumarsaw/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/priyanshukumarsaw/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Word--            --Lemma--           \n",
      "program             program             \n",
      "programming         program             \n",
      "programer           programer           \n",
      "programs            program             \n",
      "programmed          program             \n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "# Initialize wordnet lemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "# Example inflections to reduce\n",
    "example_words = [\"program\",\"programming\",\"programer\",\"programs\",\"programmed\"]\n",
    "# Perform lemmatization\n",
    "print(\"{0:20}{1:20}\".format(\"--Word--\",\"--Lemma--\"))\n",
    "for word in example_words:\n",
    "   print (\"{0:20}{1:20}\".format(word, wnl.lemmatize(word, pos=\"v\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Word--            --Lemma--           \n",
      "I                   I                   \n",
      "have                have                \n",
      "three               three               \n",
      "visions             visions             \n",
      "for                 for                 \n",
      "India               India               \n",
      "In                  In                  \n",
      "3000                3000                \n",
      "years               years               \n",
      "of                  of                  \n",
      "our                 our                 \n",
      "history             history             \n",
      "people              people              \n",
      "from                from                \n",
      "all                 all                 \n",
      "over                over                \n",
      "the                 the                 \n",
      "world               world               \n",
      "have                have                \n",
      "come                come                \n",
      "and                 and                 \n",
      "invaded             invade              \n",
      "us                  us                  \n",
      "captured            capture             \n",
      "our                 our                 \n",
      "lands               land                \n",
      "conquered           conquer             \n",
      "our                 our                 \n",
      "minds               mind                \n",
      "From                From                \n",
      "Alexander           Alexander           \n",
      "onwards             onwards             \n",
      "the                 the                 \n",
      "Greeks              Greeks              \n",
      "the                 the                 \n",
      "Turks               Turks               \n",
      "the                 the                 \n",
      "Moguls              Moguls              \n",
      "the                 the                 \n",
      "Portuguese          Portuguese          \n",
      "the                 the                 \n",
      "British             British             \n",
      "the                 the                 \n",
      "French              French              \n",
      "the                 the                 \n",
      "Dutch               Dutch               \n",
      "all                 all                 \n",
      "of                  of                  \n",
      "them                them                \n",
      "came                come                \n",
      "and                 and                 \n",
      "looted              loot                \n",
      "us                  us                  \n",
      "took                take                \n",
      "over                over                \n",
      "what                what                \n",
      "was                 be                  \n",
      "ours                ours                \n",
      "Yet                 Yet                 \n",
      "we                  we                  \n",
      "have                have                \n",
      "not                 not                 \n",
      "done                do                  \n",
      "this                this                \n",
      "to                  to                  \n",
      "any                 any                 \n",
      "other               other               \n",
      "nation              nation              \n",
      "We                  We                  \n",
      "have                have                \n",
      "not                 not                 \n",
      "conquered           conquer             \n",
      "anyone              anyone              \n",
      "We                  We                  \n",
      "have                have                \n",
      "not                 not                 \n",
      "grabbed             grab                \n",
      "their               their               \n",
      "land                land                \n",
      "their               their               \n",
      "culture             culture             \n",
      "their               their               \n",
      "history             history             \n",
      "and                 and                 \n",
      "tried               try                 \n",
      "to                  to                  \n",
      "enforce             enforce             \n",
      "our                 our                 \n",
      "way                 way                 \n",
      "of                  of                  \n",
      "life                life                \n",
      "on                  on                  \n",
      "them                them                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/priyanshukumarsaw/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "#import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "example_sentence = \"\"\"\n",
    "    I have three visions for India. In 3000 years of our history,\n",
    "    people from all over the world have come and invaded us, captured our  lands, conquered our minds.\n",
    "    From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "    the French, the Dutch, all of them came and looted us, took over what was ours.\n",
    "    Yet we have not done this to any other nation. We have not conquered anyone.\n",
    "    We have not grabbed their land, their culture,\n",
    "    their history and tried to enforce our way of life on them.\n",
    "    \"\"\"\n",
    "\n",
    "# Remove punctuation\n",
    "example_sentence_no_punct = example_sentence.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "word_tokens = word_tokenize(example_sentence_no_punct)\n",
    "\n",
    "# Initialize WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# Perform lemmatization\n",
    "print(\"{0:20}{1:20}\".format(\"--Word--\", \"--Lemma--\"))\n",
    "for word in word_tokens:\n",
    "    print(\"{0:20}{1:20}\".format(word, wnl.lemmatize(word, pos=\"v\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
